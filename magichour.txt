Preprocessing output: 
Transforms the original log file into an iterable of LogLine named tuples.
Transformation rules (regexp) are not required but highly recommended for template creation.

DistributedLogLine(ts=1543556340.0, text='ip-172-31-27-153 CRON[21882]: pam_unix(cron:session): session closed for user root', processed='IPADDR CRON[INT]: pam_unix(cron:session): session closed for USER', proc_dict={'INT': ['21882'], 'IPADDR': ['ip-172-31-27-153'], 'USER': ['user root']}, template=None, templateId=None, template_dict=None)

Magichour maintains the replacements in the LogLine named tuple to enable reconstruction of LogLines throughout the pipeline.

Template generation output:
Transforms the outcome of the previous step to an iterable of Template named tuples.
Two different algorithms used for template generation: LogCluster and StringMatch. The example below was generated by LogCluster.

DistributedTemplateLine(id=0, template=<_sre.SRE_Pattern object at 0x5624d79cd3e0>, skip_words=[], raw_str='IPADDR sshd[INT]: Address IPADDR maps to structuredsettlement-AFILE, but this does not map back to the address - POSSIBLE BREAK-IN ATTEMPT!')

Next step: apply the appropriate template to each line in the log file (recommended to be performed in a streaming fashion). This step produces an iterable of TimedTemplate named tuples, representing the instances of each template that were found in the log file. If the template_id is -1 in a TimedTemplate, then that means that no template was found that matches that particular line.

DistributedLogLine(ts=1543556340.0, text='ip-172-31-27-153 CRON[21882]: pam_unix(cron:session): session closed for user root', processed='IPADDR CRON[INT]: pam_unix(cron:session): session closed for USER', proc_dict={'INT': ['21882'], 'IPADDR': ['ip-172-31-27-153'], 'USER': ['user root']}, template='IPADDR\\ CRON\\[INT\\]\\:\\ pam\\_unix\\(cron\\:session\\)\\:\\ session\\ closed\\ for\\ USER$', templateId=50, template_dict=defaultdict(<type 'list'>, {}))

Event detection output:
First, the output of the previous step is split into time-based windows. For the event detection, two algorithms are provided: fp_growth and PARIS. Due to some issues with fp_growth, only PARIS was tested. 

Event(id='7d1d3c05-76ea-4b01-92da-739899244c6d', template_ids=frozenset([53, 62]))

Apply events:

Create timed templates by applying templates generated from the last step (Template) over an iterable of LogLines.

The way this currently works is by determining which template for each event is the least frequently occurring template in timed_templates. By using the least frequently occuring template, we are guaranteed to not discover more than the maximum number of events allowed in a given list of timed_templates.

For each event's least frequently occurring template, we construct a "window" around each instance in timed_templates, where a "window" is a collection of all of the timed_templates that occurred within the specified window size (60 secs by default). Within each window, for each of the remaining template types belonging to the event in question, we say that the logline with the highest Jaccard similarity score between its replacement values and the original frequently occuring template's replacement values. The logic here is that the closer the Jaccard similarity score, the more likely that the two loglines are talking about the same (machine, IP address, etc.).
